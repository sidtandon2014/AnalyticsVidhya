{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitandon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# prepare the image for the VGG model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "productMatrix = pd.read_csv(\"./data/train/ProductMatrix\")\n",
    "\n",
    "totalClasses = len(np.unique(productMatrix[\"TargetCode\"]))\n",
    "train,test = train_test_split(productMatrix,test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.groupby(\"TargetCode\").count().sort_values(by = \"productid\",ascending = False)\n",
    "submissionDFUsers = pd.read_csv(\"./data/test.csv\")\n",
    "txnDF = pd.read_csv(\"./data/train/train.csv\")\n",
    "productAggData = txnDF.groupby([\"productid\",\"UserId\"])[\"Quantity\"].count().reset_index()\n",
    "productAggData.columns = [\"productid\",\"UserId\",\"PurchaseCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageLoader(data, batch_size):\n",
    "    \n",
    "    L = len(data)\n",
    "    \n",
    "    def loadImageAndTarget(df):\n",
    "        imagesList = []\n",
    "        targetList = []\n",
    "        \n",
    "        for row in df.values:\n",
    "            imagePath = os.path.join(\"./data/train/images\",str(row[0]) + \".jpg\")\n",
    "            targets = np.zeros(shape = (1,totalClasses),dtype = \"int\")\n",
    "            targets[0,row[1]]= 1\n",
    "            image = load_img(imagePath, target_size=(img_rows, img_cols))\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "            imagesList.append(image)\n",
    "            targetList.append(targets)\n",
    "        return imagesList,targetList\n",
    "        \n",
    "        \n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            \n",
    "            X,Y = loadImageAndTarget(data[batch_start:limit])\n",
    "            \n",
    "            X=np.asarray(X).reshape(-1,img_rows, img_cols,img_channel)\n",
    "            Y = np.asarray(Y).reshape(-1,totalClasses)\n",
    "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitandon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n"
     ]
    }
   ],
   "source": [
    "#--------Define the model\n",
    "model = VGG16(weights=None,include_top=False,input_shape=(img_rows, img_cols, img_channel),classes = totalClasses)\n",
    "model.load_weights(\"./data/train/weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",by_name=True)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "keras_input = Input(shape=(img_rows,img_cols,img_channel),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model(keras_input)\n",
    "\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "x = Dense(totalClasses, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=keras_input , output=x)\n",
    "\n",
    "optim = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#optim = optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=1e-6)\n",
    "#optim = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "85/85 [==============================] - 60s 706ms/step - loss: 3.0848 - acc: 0.8037 - val_loss: 3.1208 - val_acc: 0.8021\n",
      "Epoch 2/10\n",
      "85/85 [==============================] - 63s 747ms/step - loss: 3.1747 - acc: 0.8007 - val_loss: 3.1809 - val_acc: 0.7970\n",
      "Epoch 3/10\n",
      "85/85 [==============================] - 59s 698ms/step - loss: 3.1473 - acc: 0.7996 - val_loss: 3.1517 - val_acc: 0.7934\n",
      "Epoch 4/10\n",
      "85/85 [==============================] - 61s 720ms/step - loss: 3.0747 - acc: 0.8073 - val_loss: 3.1075 - val_acc: 0.8007\n",
      "Epoch 5/10\n",
      "85/85 [==============================] - 63s 742ms/step - loss: 3.0229 - acc: 0.8080 - val_loss: 3.1963 - val_acc: 0.7970\n",
      "Epoch 6/10\n",
      "85/85 [==============================] - 64s 748ms/step - loss: 3.0416 - acc: 0.8047 - val_loss: 2.7931 - val_acc: 0.8155\n",
      "Epoch 7/10\n",
      "85/85 [==============================] - 65s 761ms/step - loss: 2.9608 - acc: 0.8110 - val_loss: 3.0539 - val_acc: 0.7970\n",
      "Epoch 8/10\n",
      "85/85 [==============================] - 66s 772ms/step - loss: 2.9031 - acc: 0.8180 - val_loss: 3.2540 - val_acc: 0.7823\n",
      "Epoch 9/10\n",
      "85/85 [==============================] - 66s 781ms/step - loss: 2.8641 - acc: 0.8198 - val_loss: 3.0077 - val_acc: 0.8007\n",
      "Epoch 10/10\n",
      "85/85 [==============================] - 66s 781ms/step - loss: 2.8524 - acc: 0.8213 - val_loss: 3.3668 - val_acc: 0.7823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2827bc24080>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGenerator = imageLoader(train,batch_size)\n",
    "testGenerator = imageLoader(test,batch_size)\n",
    "fullDataGenerator = imageLoader(productMatrix,batch_size)\n",
    "my_model.fit_generator(trainGenerator\n",
    "                    ,steps_per_epoch= train.shape[0] // batch_size\n",
    "                    , epochs=10\n",
    "                    , validation_data = testGenerator\n",
    "                    , validation_steps = test.shape[0] // batch_size\n",
    "                    , verbose = 1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a second Model\n",
    "intermediate_model = Model(inputs=my_model.layers[0].input, \n",
    "                              outputs=my_model.get_layer(\"fc2\").output)\n",
    "output = intermediate_model.predict_generator(fullDataGenerator\n",
    "                                     , steps= (productMatrix.shape[0] // batch_size) + 1\n",
    "                                    )\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "productSimilarityMatrix = cosine_similarity(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>TargetCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11139192</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11139194</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11139524</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11139560</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11139588</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   productid  TargetCode\n",
       "0   11139192           6\n",
       "1   11139194           6\n",
       "2   11139524           8\n",
       "3   11139560           8\n",
       "4   11139588           6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productMatrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([productMatrix[[\"productid\"]]\n",
    "           ,pd.DataFrame(productSimilarityMatrix)],axis = 1)\n",
    "\n",
    "mergedDF = productAggData[[\"UserId\",\"productid\"]].merge(tmp, how = \"inner\",on = \"productid\", suffixes = \"_y\")\n",
    "cols = mergedDF.columns[2:]\n",
    "aggMergedDF = mergedDF.groupby(\"UserId\")[cols].agg(['count','sum'])\n",
    "aggMergedDF.columns = [str(col[0]) + \"_\" + col[1] for col in aggMergedDF.columns]\n",
    "for col in cols:\n",
    "    aggMergedDF[str(col) + \"_sum\"] = aggMergedDF[str(col) + \"_sum\"]/ aggMergedDF[\"0_count\"]\n",
    "aggMergedDF = aggMergedDF[[str(col) + \"_sum\" for col in cols]]\n",
    "aggMergedDF.columns = [str(col).replace(\"_sum\",\"\") for col in aggMergedDF.columns]\n",
    "\n",
    "simArrPerUser = np.asarray(aggMergedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27778, 3026)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggMergedDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3026, 1024) (3026, 2)\n"
     ]
    }
   ],
   "source": [
    "print(output.shape, productMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1864,    1, ...,  906, 2842,  846], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(-1 * similarity[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -1 * np.array([[1,0,2],[4,1,0]])\n",
    "tmp = pd.DataFrame()\n",
    "#np.argsort(x,axis = 1)\n",
    "for index in range(x.shape[0]):\n",
    "    tmp = pd.concat([tmp,pd.DataFrame({\"Similarity\":[','.join(str(a) for a in x[index,:])]})],axis = 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>TargetCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11139192</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>12657628</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11139194</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      productid  TargetCode\n",
       "0      11139192           6\n",
       "1864   12657628           5\n",
       "1      11139194           6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productMatrix.loc[[0,1864,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendProductsForUserId(UserID, totalRecommendations):\n",
    "    #UserID = 26784\n",
    "    global simArrPerUser,aggMergedDF,productAggData\n",
    "\n",
    "    UserSpecificProducts = set(productAggData[productAggData[\"UserId\"] == UserID][\"productid\"])\n",
    "    \n",
    "    allProducts = productMatrix[[\"productid\"]].values\n",
    "    UserIDs = aggMergedDF.index.values\n",
    "    UserIDIndex = np.where(UserIDs == UserID)\n",
    "    \n",
    "    productIds = []\n",
    "    productSortedSimilarity = np.argsort(-1 * simArrPerUser[UserIDIndex,:]).reshape(1,-1)\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    for index in range(productSortedSimilarity.shape[1]):\n",
    "        productIndex = productSortedSimilarity[0,index]\n",
    "        if allProducts[productIndex][0] not in UserSpecificProducts:\n",
    "            productIds.append(allProducts[productIndex][0])\n",
    "    \n",
    "    \n",
    "    return productIds[0:totalRecommendations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "for user in submissionDFUsers[\"UserId\"].values:\n",
    "    recommendations = \"[\" + \",\".join(str(prod) for prod in recommendProductsForUserId(user,10)) + \"]\"\n",
    "    submission = pd.concat([submission,pd.DataFrame({\"UserId\":[user],\"product_list\":[recommendations]})], axis = 0)\n",
    "\n",
    "submission.to_csv(\"./Data/submission.csv\",index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13039832,\n",
       " 12658066,\n",
       " 11660062,\n",
       " 12657954,\n",
       " 11659884,\n",
       " 13039834,\n",
       " 11660210,\n",
       " 11481030,\n",
       " 12407706,\n",
       " 12407188]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendProductsForUserId(2,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
