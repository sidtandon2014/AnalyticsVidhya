{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitandon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.utils.vis_utils import plot_model\n",
    "# prepare the image for the VGG model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_channel = 224, 224, 3\n",
    "productMatrix = pd.read_csv(\"./data/train/ProductMatrix\")\n",
    "\n",
    "totalClasses = len(np.unique(productMatrix[\"TargetCode\"]))\n",
    "train,test = train_test_split(productMatrix,test_size = .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.groupby(\"TargetCode\").count().sort_values(by = \"productid\",ascending = False)\n",
    "submissionDFUsers = pd.read_csv(\"./data/test.csv\")\n",
    "txnDF = pd.read_csv(\"./data/train/train.csv\")\n",
    "productAggData = txnDF.groupby([\"productid\",\"UserId\"])[\"Quantity\"].count().reset_index()\n",
    "productAggData.columns = [\"productid\",\"UserId\",\"PurchaseCount\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for row in train[0:10].values:\n",
    "    x = np.array(row[0])\n",
    "    tmp.append(x)\n",
    "np.asarray(tmp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(productMatrix[\"TargetCode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageLoader(data, batch_size):\n",
    "    \n",
    "    L = len(data)\n",
    "    \n",
    "    def loadImageAndTarget(df):\n",
    "        imagesList = []\n",
    "        targetList = []\n",
    "        \n",
    "        for row in df.values:\n",
    "            imagePath = os.path.join(\"./data/train/images\",str(row[0]) + \".jpg\")\n",
    "            targets = np.zeros(shape = (1,totalClasses),dtype = \"int\")\n",
    "            targets[0,row[1]]= 1\n",
    "            image = load_img(imagePath, target_size=(img_rows, img_cols))\n",
    "            # convert the image pixels to a numpy array\n",
    "            image = img_to_array(image)\n",
    "            imagesList.append(image)\n",
    "            targetList.append(targets)\n",
    "        return imagesList,targetList\n",
    "        \n",
    "        \n",
    "    #this line is just to make the generator infinite, keras needs that    \n",
    "    while True:\n",
    "\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            \n",
    "            X,Y = loadImageAndTarget(data[batch_start:limit])\n",
    "            \n",
    "            X=np.asarray(X).reshape(-1,img_rows, img_cols,img_channel)\n",
    "            Y = np.asarray(Y).reshape(-1,totalClasses)\n",
    "            yield (X,Y) #a tuple with two numpy arrays with batch_size samples     \n",
    "\n",
    "            batch_start += batch_size   \n",
    "            batch_end += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sitandon\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"im..., outputs=Tensor(\"pr...)`\n"
     ]
    }
   ],
   "source": [
    "#--------Define the model\n",
    "model = VGG16(weights=None,include_top=False,input_shape=(img_rows, img_cols, img_channel),classes = totalClasses)\n",
    "model.load_weights(\"./data/train/weights/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",by_name=True)\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "keras_input = Input(shape=(img_rows,img_cols,img_channel),name = 'image_input')\n",
    "\n",
    "#Use the generated model \n",
    "output_vgg16_conv = model(keras_input)\n",
    "\n",
    "x = Flatten(name='flatten')(output_vgg16_conv)\n",
    "x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "x = Dense(1024, activation='relu', name='fc2')(x)\n",
    "x = Dense(totalClasses, activation='softmax', name='predictions')(x)\n",
    "\n",
    "#Create your own model \n",
    "my_model = Model(input=keras_input , output=x)\n",
    "\n",
    "optim = optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#optim = optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=1e-6)\n",
    "#optim = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "\n",
    "#In the summary, weights and layers from VGG part will be hidden, but they will be fit during the training\n",
    "#my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 62s 735ms/step - loss: 5.1368 - acc: 0.6752 - val_loss: 5.8261 - val_acc: 0.5868\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 64s 766ms/step - loss: 3.9893 - acc: 0.7453 - val_loss: 4.3953 - val_acc: 0.7148\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 66s 783ms/step - loss: 3.7114 - acc: 0.7657 - val_loss: 4.5384 - val_acc: 0.7185\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 69s 823ms/step - loss: 3.6892 - acc: 0.7663 - val_loss: 4.5013 - val_acc: 0.7185\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 70s 837ms/step - loss: 3.4901 - acc: 0.7771 - val_loss: 4.2473 - val_acc: 0.7222\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 77s 912ms/step - loss: 3.2630 - acc: 0.7910 - val_loss: 3.7630 - val_acc: 0.7593\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 80s 954ms/step - loss: 3.2098 - acc: 0.7951 - val_loss: 3.9197 - val_acc: 0.7444\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 87s 1s/step - loss: 3.2164 - acc: 0.7958 - val_loss: 3.7443 - val_acc: 0.7519\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 89s 1s/step - loss: 3.0896 - acc: 0.8047 - val_loss: 4.2026 - val_acc: 0.7333\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 92s 1s/step - loss: 3.0748 - acc: 0.8044 - val_loss: 4.1876 - val_acc: 0.7370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x281e90d6780>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGenerator = imageLoader(train,batch_size)\n",
    "testGenerator = imageLoader(test,batch_size)\n",
    "fullDataGenerator = imageLoader(productMatrix,batch_size)\n",
    "my_model.fit_generator(trainGenerator\n",
    "                    ,steps_per_epoch= train.shape[0] // batch_size\n",
    "                    , epochs=10\n",
    "                    , validation_data = testGenerator\n",
    "                    , validation_steps = test.shape[0] // batch_size\n",
    "                    , verbose = 1\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a second Model\n",
    "intermediate_model = Model(inputs=my_model.layers[0].input, \n",
    "                              outputs=my_model.get_layer(\"fc2\").output)\n",
    "output = intermediate_model.predict_generator(fullDataGenerator\n",
    "                                     , steps= (productMatrix.shape[0] // batch_size) + 1\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3015, 1024) (3015, 2)\n"
     ]
    }
   ],
   "source": [
    "print(output.shape, productMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "productSimilarityMatrix = cosine_similarity(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1864,    1, ...,  906, 2842,  846], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(-1 * similarity[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = -1 * np.array([[1,0,2],[4,1,0]])\n",
    "tmp = pd.DataFrame()\n",
    "#np.argsort(x,axis = 1)\n",
    "for index in range(x.shape[0]):\n",
    "    tmp = pd.concat([tmp,pd.DataFrame({\"Similarity\":[','.join(str(a) for a in x[index,:])]})],axis = 0)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(x,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>productid</th>\n",
       "      <th>TargetCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11139192</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>12657628</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11139194</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      productid  TargetCode\n",
       "0      11139192           6\n",
       "1864   12657628           5\n",
       "1      11139194           6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productMatrix.loc[[0,1864,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendProductsForUserId(UserID, totalRecommendations):\n",
    "    #UserID = 26784\n",
    "    global productSimilarityMatrix,productMatrix,productAggData\n",
    "    \n",
    "    train = productMatrix\n",
    "\n",
    "    UserSpecificProducts = set(productAggData[productAggData[\"UserId\"] == UserID][\"productid\"])\n",
    "    AllProdsNotPurchaseByThisUser = set(productAggData[\"productid\"]) - UserSpecificProducts\n",
    "\n",
    "    allProducts = productMatrix[\"productid\"].values #productMatrix.index.values\n",
    "\n",
    "    simDF = pd.DataFrame()\n",
    "    for nonPurchasedItem in list(AllProdsNotPurchaseByThisUser):\n",
    "        #pdb.set_trace()\n",
    "        sim = 0\n",
    "        nonPurchasedItemIndexInProductMatrix = np.where(allProducts == nonPurchasedItem)\n",
    "\n",
    "        for purchasedItem in list(UserSpecificProducts):\n",
    "            purchasedItemIndexInProductMatrix = np.where(allProducts == purchasedItem)\n",
    "            sim += productSimilarityMatrix[purchasedItemIndexInProductMatrix,nonPurchasedItemIndexInProductMatrix]\n",
    "        sim = sim / len(UserSpecificProducts)\n",
    "\n",
    "        simDF = pd.concat([simDF,pd.DataFrame({\"ProductId\":[nonPurchasedItem],\"Sim\":[sim]})])\n",
    "        simDF = simDF.sort_values(by = \"Sim\",ascending = False).head(totalRecommendations)\n",
    "\n",
    "    if len(simDF) < totalRecommendations:\n",
    "        tmp = (productAggData[productAggData[\"UserId\"] == UserID]\n",
    "               .sort_values(by = \"PurchaseCount\", ascending = False)\n",
    "               .head(10 - len(simDF))\n",
    "              )\n",
    "\n",
    "        simDF = pd.concat([simDF,pd.DataFrame({\"ProductId\":tmp[\"productid\"],\"Sim\":tmp[\"PurchaseCount\"]})])\n",
    "    return simDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "for user in submissionDFUsers[\"UserId\"].values:\n",
    "    recommendations = \"[\" + \",\".join(str(prod) for prod in recommendProductsForUserId(user,10)[\"ProductId\"].values) + \"]\"\n",
    "    submission = pd.concat([submission,pd.DataFrame({\"UserId\":[user],\"product_list\":[recommendations]})], axis = 0)\n",
    "\n",
    "submission.to_csv(\"./Data/submission.csv\",index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000001 , 0.8467357 , 0.54576415, ..., 0.58784515, 0.53183925,\n",
       "        0.47712192],\n",
       "       [0.8467357 , 1.0000002 , 0.5081514 , ..., 0.5530091 , 0.48624814,\n",
       "        0.4480817 ],\n",
       "       [0.54576415, 0.5081514 , 0.9999999 , ..., 0.87206924, 0.8481258 ,\n",
       "        0.5320573 ],\n",
       "       ...,\n",
       "       [0.58784515, 0.5530091 , 0.87206924, ..., 1.0000001 , 0.8407767 ,\n",
       "        0.5221985 ],\n",
       "       [0.53183925, 0.48624814, 0.8481258 , ..., 0.8407767 , 1.        ,\n",
       "        0.5316389 ],\n",
       "       [0.47712192, 0.4480817 , 0.5320573 , ..., 0.5221985 , 0.5316389 ,\n",
       "        1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productSimilarityMatrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
